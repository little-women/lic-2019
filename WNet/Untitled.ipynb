{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading prepared vocab from ./data/demo_30000.vocab.pt ...\n",
      "Vocabulary size of fields: SRC-30004 TGT-30004 CUE-30004\n",
      "Loading prepared data from ./data/demo_30000.data.pt ...\n",
      "Number of examples: TRAIN-89901 VALID-9054 TEST-9054\n",
      "Read 9054 VALID examples (0 filtered)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 9054/9054 [00:01<00:00, 7941.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from source.inputters.corpus import KnowledgeCorpus\n",
    "corpus = KnowledgeCorpus('./data/', 'demo', max_len=500, max_vocab_size=30000, share_vocab=True)\n",
    "corpus.load()\n",
    "valid_raw = corpus.read_data('./data/demo.dev', data_type='valid')\n",
    "valid_data = corpus.build_examples(valid_raw)\n",
    "\n",
    "from source.inputters.dataset import Dataset\n",
    "data = Dataset(valid_data)\n",
    "loader = data.create_batches(5)\n",
    "for input in loader:\n",
    "    input = input\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_inputs = input\n",
    "# y(t-1)\n",
    "dec_inputs = input.tgt[0][:, :-1], input.tgt[1] - 1\n",
    "# y(t)\n",
    "target = input.tgt[0][:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   2,   30,    4,    8,    8,   36,    4,   29,   96,    3,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,   30,    4,    8,    8,   36,    4,   29,   45,   26,   50,   11,\n",
       "            37,  292,   45,   26,   50,   11,   10,    3,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,   30,    4,    8,    8,   36,    4,   29,   45,   26,   50,   11,\n",
       "            37,  292,   45,   26,   50,   11,   10,  183,  807,    6,    4,   88,\n",
       "            16,   26,  222,   10,   62,  110,   10,  917,    6,   21,   26,   55,\n",
       "             6,  139,   62,   10,    3,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0],\n",
       "         [   2,   30,    4,    8,    8,   36,    4,   29,   45,   26,   50,   11,\n",
       "            37,  292,   45,   26,   50,   11,   10,  183,  807,    6,    4,   88,\n",
       "            16,   26,  222,   10,   62,  110,   10,  917,    6,   21,   26,   55,\n",
       "             6,  139,   62,   10,  173,    6,   21,   79,  135,   62,    6, 4578,\n",
       "            25,    8,  207,    6,  429,   90,   95,   85,   20, 3335,  418,    7,\n",
       "          1252,    1,   10,  744,    6,  444,   10,    3],\n",
       "         [   2,   30,    4,    9,    4,   15,   50,    9,   15,   50,   29,   96,\n",
       "             3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0]]),\n",
       " tensor([10, 20, 41, 68, 13]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_inputs.src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.models.pgnet import PointerNet\n",
    "model = PointerNet(corpus.SRC.vocab_size, 300, 800, padding_idx=corpus.padding_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs, dec_init_state = model.encode(enc_inputs, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_init_state.fact_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    4,    12,    11,     3,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     4,    22,\n",
       "        26107,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     4,    17,    28,    21,\n",
       "          161,  7378,   355, 11000,     6,   153,  2381,   752,    39,     3,\n",
       "            0,     0,     0,     0,     4,   104,   205,     3,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     8,    34,     1,   418,     7,  1252,     1,     3,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            8,    36,  7961,     3,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     8,   182,\n",
       "          179,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     8,    35,    58,     3,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     8,    32,    38,     3,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     8,    12,    23,     3,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            8,    66,   288,     3,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     4,    17,\n",
       "           28,  7378,    11,     6,   100,  1475,   548,   292,   292,     7,\n",
       "          837,   365,   990,     7,  2273,    10,     4,    15,    50,     3,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_init_state.fact[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_inputs, _ = dec_inputs\n",
    "input = dec_inputs[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_vocab, p_mode, attn_f, attn_h, fact, hist = model.decoder.decode(input, dec_init_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_prob = prob_vocab * p_mode[:, :, 0].unsqueeze(1)\n",
    "weighted_f = attn_f * p_mode[:, :, 1].unsqueeze(1)\n",
    "weighted_h = attn_h * p_mode[:, :, 2].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.utils.misc import convert_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_prob = convert_dist(\n",
    "                weighted_h, hist, weighted_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_prob = convert_dist(\n",
    "                weighted_f, fact, weighted_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0144, 0.0148, 0.0143, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0137, 0.0150, 0.0139, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0145, 0.0139, 0.0133, 0.0119, 0.0141, 0.0138, 0.0145, 0.0168, 0.0157,\n",
       "         0.0137, 0.0134, 0.0155, 0.0136, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0147, 0.0162, 0.0146, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0127, 0.0149, 0.0148, 0.0152, 0.0148, 0.0152, 0.0148, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0130, 0.0157, 0.0180, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0123, 0.0129, 0.0163, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0136, 0.0164, 0.0165, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0133, 0.0146, 0.0145, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0133, 0.0155, 0.0165, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0133, 0.0153, 0.0159, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0144, 0.0138, 0.0135, 0.0129, 0.0137, 0.0152, 0.0157, 0.0153, 0.0158,\n",
       "         0.0158, 0.0144, 0.0142, 0.0154, 0.0173, 0.0152, 0.0146, 0.0157, 0.0169,\n",
       "         0.0146, 0.0156, 0.0146, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_f[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_facts, fact, hist, out_hists, prob_vocab, prob_hist, prob_fact, p_modes = model(enc_inputs, dec_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(enc_inputs, dec_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading prepared vocab from ./data/hsrc_30000.vocab.pt ...\n",
      "Vocabulary size of fields: SRC-30004 TGT-30004 CUE-30004\n",
      "Loading prepared data from ./data/hsrc_30000.data.pt ...\n",
      "Number of examples: TRAIN-89901 VALID-9054 TEST-9054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 9054/9054 [00:01<00:00, 8838.20it/s]\n"
     ]
    }
   ],
   "source": [
    "from source.inputters.corpus2 import HieraSrcCorpus\n",
    "corpus = HieraSrcCorpus('./data/', 'hsrc', max_len=500, max_vocab_size=30000, share_vocab=True)\n",
    "corpus.load()\n",
    "\n",
    "valid_raw = corpus.read_data('./data/hsrc.dev', data_type='valid')\n",
    "valid_data = corpus.build_examples(valid_raw)\n",
    "\n",
    "from source.inputters.dataset import Dataset\n",
    "data = Dataset(valid_data)\n",
    "loader = data.create_batches(5)\n",
    "for input in loader:\n",
    "    input = input\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[   2,   29,    4,    8,    8,   35,    4,    3,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   2,   95,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0]],\n",
       " \n",
       "         [[   2,   29,    4,    8,    8,   35,    4,    3,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   2,   44,   26,   49,   11,   36,  291,    3,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   2,   44,   26,   49,   11,   10,    3,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0]],\n",
       " \n",
       "         [[   2,   29,    4,    8,    8,   35,    4,    3,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   2,   44,   26,   49,   11,   36,  291,    3,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   2,   44,   26,   49,   11,   10,    3,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   2,  182,  807,    6,    4,   87,   16,   26,  221,   10,   61,\n",
       "            109,   10,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   2,  917,    6,   21,   26,   54,    6,  138,   61,   10,    3,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0]],\n",
       " \n",
       "         [[   2,   29,    4,    8,    8,   35,    4,    3,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   2,   44,   26,   49,   11,   36,  291,    3,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   2,   44,   26,   49,   11,   10,    3,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   2,  182,  807,    6,    4,   87,   16,   26,  221,   10,   61,\n",
       "            109,   10,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   2,  917,    6,   21,   26,   54,    6,  138,   61,   10,    3,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   2,  172,    6,   21,   78,  134,   61,    6, 4580,   25,    8,\n",
       "            206,    6,  428,   89,   94,   84,   20, 3335,  417,    7, 1252,\n",
       "              1,   10,    3],\n",
       "          [   2,  744,    6,  443,   10,    3,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0]],\n",
       " \n",
       "         [[   2,   29,    4,    9,    4,   15,   49,    9,   15,   49,    3,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   2,   95,    3,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0],\n",
       "          [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "              0,    0,    0]]]), tensor([[ 8,  3,  0,  0,  0,  0,  0],\n",
       "         [ 8,  8,  7,  0,  0,  0,  0],\n",
       "         [ 8,  8,  7, 14, 11,  0,  0],\n",
       "         [ 8,  8,  7, 14, 11, 25,  6],\n",
       "         [11,  3,  0,  0,  0,  0,  0]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.modules.embedder import Embedder\n",
    "from source.modules.encoders.rnn_encoder import RNNEncoder\n",
    "from source.modules.encoders.rnn_encoder import HRNNEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = Embedder(num_embeddings=corpus.SRC.vocab_size,\n",
    "                                embedding_dim=300,\n",
    "                                padding_idx=corpus.padding_idx)\n",
    "sub_encoder = RNNEncoder(input_size=300,\n",
    "                          hidden_size=800,\n",
    "                          embedder=embedder,\n",
    "                          num_layers=1,\n",
    "                          bidirectional=False,\n",
    "                          dropout=0.0)\n",
    "hiera_encoder = RNNEncoder(input_size=800,\n",
    "                          hidden_size=800,\n",
    "                          num_layers=1,\n",
    "                          bidirectional=False,\n",
    "                          dropout=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = HRNNEncoder(sub_encoder, hiera_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, lengths = input.src\n",
    "batch_size, max_hiera_len, max_sub_len = indices.size()\n",
    "hiera_lengths = lengths.gt(0).long().sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 5, 7, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiera_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiera_outputs, hiera_hidden, _ = encoder(input.src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 7, 800])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiera_outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 800])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiera_hidden.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.models.hseq2seq import HSeq2Seq\n",
    "model = HSeq2Seq(corpus.SRC.vocab_size, corpus.SRC.vocab_size, 300, 800, padding_idx=corpus.padding_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({}, <source.modules.decoders.state.DecoderState at 0x26bb5007c50>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encode(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp",
   "language": "python",
   "name": "anlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
